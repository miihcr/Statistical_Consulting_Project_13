---
title: "3_analysis"
author: "Milena Costa"
date: "2025-11-03"
output: pdf_document
---

```{r setup, include=FALSE}

source(here::here("R","_common.R"), local = knitr::knit_global())

# Load processed data written by 1_dataprep

df_wide <- readRDS(here::here("data","processed","df_wide.rds"))
df_long <- readRDS(here::here("data","processed","df_long.rds"))


# set options
options(contrasts=c("contr.treatment", "contr.poly"))

# Control
ctrl <- glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 1e6))


```

# 1. Statistical Analysis

## Research Question 1 

```{r}

# Baseline model (intercept only)

m0 <- glmer(
  choice ~ (1 | ppn) + (1 | class),
  data = df_long, family = binomial, control = ctrl
)

# Step 1: Test whether classroom random intercept is needed

m1 <- glmer(
  choice ~ target*group*block + reward*effort + school +
    (1 | ppn) + (1 | class),
  data = df_long, family = binomial, control = ctrl
)

m1_simpler <- glmer(
  choice ~ target*group*block + reward*effort + school +
    (1 | ppn),
  data = df_long, family = binomial, control = ctrl
)

# Compare models
print(anova(m1_simpler, m1, test = "Chisq"))
print(isSingular(m1))
print(VarCorr(m1))



# Step 2: Add random slope for Block
m_full <- glmer(
  choice ~ target*group*block + reward*effort + school +
    (1 + block | ppn),
  data = df_long, family = binomial, control = ctrl
)

# Compare models

print(anova(m1_simpler, m_full, test = "Chisq")) # full model is better
isSingular(m_full)
print(VarCorr(m_full))


# Step 3: test the 3-way interaction

m_no_3way <- glmer(
  choice ~ target + group + block + 
    target:group + target:block + group:block +  # all 2-way interactions
    reward * effort + school +
    (1 + block | ppn),
  data = df_long, family = binomial, control = ctrl
)

anova(m_no_3way, m_full, test = "Chisq") # model without 3way is better

# Choose final model 
final_model <- m_full


```


## Model Summary and Odds Ratios

```{r}


print(summary(final_model))

# Overall model fit

print(anova(m0, final_model, test = "Chisq"))

# Odds ratio with 95% CIs
se <- sqrt(diag(vcov(final_model)))

log_odds <- fixef(final_model)
tab <- data.frame(
  OR = exp(log_odds),
  LL = exp(log_odds - 1.96 * se),
  UL = exp(log_odds + 1.96 * se)
)
print(round(tab, 3))


 
coefs <- summary(final_model)$ coefficients[, "Estimate"]
std.err <- summary(final_model)$ coefficients[, "Std. Error"]
nams <- rownames(summary(final_model)$ coefficients)



```


## 2. Post-hoc Analyses 

### 1. Reward $\times$ Effort interaction


```{r}

# 1. EMM for all combinations of reward x effort

emm_re <- emmeans(final_model, ~ reward * effort, type = "response")


# 2. Pairwise comparisons 

# Reward effects within each effort level: Do high rewards increase choice probability equally at 40% and 90% effort?

contrast(emm_re, "pairwise", by = "effort", adjust = "holm")


# Effort effects within each reward level: Is 90% chosen less often than 40% at each reward magnitude?

contrast(emm_re, "pairwise", by = "reward", adjust = "holm")

# Visualization

emmip(final_model, effort ~ reward, CIs = TRUE, type = "response") +
  labs(title = "Predicted Probability of High-Effort Choice",
       y = "P(High-Effort Choice)",
       x = "Reward (points)")

```



### 2. Target $\times$ Group interaction


```{r}

# 1. EMM for all combinations of target x group

emm_tg <- emmeans(final_model, ~ target * group, type = "response")



# 2. Pairwise comparisons 


# Target differences within each group: Do groups differ in how they respond to Self vs Climate vs Prosocial cues?


contrast(emm_tg, "pairwise", by = "group", adjust = "holm")
  
  
# Group differences within each target: Do the norm groups differ in climate choices overall (pre+post averaged)?

contrast(emm_tg, "pairwise", by = "target", adjust = "holm")

# Visualization

emmip(emm_tg, group ~ target, CIs = TRUE, type = "response") +
  labs(title = "Predicted Probability of High-Effort Choice",
       y = "P(High-Effort Choice)",
       x = "Social Target")


```


### 3. Block × Group × Target: Difference-in-Differences Analysis

```{r}

# EMM for the full 3 way interaction
emm_tgb <- emmeans(m_full, ~ target * group * block, type = "response")

emm_tgb

# Pre-to-Post changes within each target × group combination

prepost_tgb <- contrast(emm_tgb, method="revpairwise", by = c("target","group"),
                        type = "response")
# Difference-in-Differences: Compare pre-post changes across groups for each target


did_by_target <- contrast(
  emm_tgb,
  interaction = c("pairwise", "revpairwise"),  # group pairwise, block revpairwise
  by = "target",
  adjust = "holm",
  type = "response"
)

print(did_by_target)

# Visualization
emmip(final_model, group ~ block | target, type = "response", CIs = TRUE) +
  labs(title = "Predicted Probability of High-Effort Choice",
       y = "P(High-Effort Choice)",
       x = "Block") 


# Create a summary of the DID analysis for easy reporting
did_summary <- as.data.frame(did_by_target)
print(did_summary)

```

### Diagnostics (final_model)

```{r}

df_complete <- df_long[complete.cases(df_long), ]

set.seed(123)
res <- simulateResiduals(final_model, n=1000)
plot(res)

# DHARMa diagnostics 
plot(res)
testUniformity(res)
testDispersion(res)       
testOutliers(res)

plotResiduals(res, df_complete$group)
plotResiduals(res, df_complete$target)
 
print(VarCorr(final_model))
print(performance::icc(final_model))
print(performance::check_collinearity(final_model))




```

## Research Question 2: Moderation Analysis

We decide to use separate models for climate trials

```{r}

# Filter for climate trials only


df_climate <- df_long |>  filter(target == "climate")


# Susceptibility Moderation
m_suscept_base <- glmer(
  choice ~ group * block + susceptibility_c + reward * effort + school +
    (1 + block | ppn),
  data = df_climate, family = binomial,
  control = ctrl
)

m_suscept_mod <- glmer(
  choice ~ group * block * susceptibility_c + reward * effort + school +
    (1 + block | ppn),
  data = df_climate, family = binomial,
  control = ctrl
)

anova(m_suscept_base, m_suscept_mod)
summary(m_suscept_mod)

#  Cohesion Moderation 
m_cohesion_base <- glmer(
  choice ~ group * block + cohesion_c + reward * effort + school +
    (1 + block | ppn),
  data = df_climate, family = binomial,
  control = ctrl
)

m_cohesion_mod <- glmer(
  choice ~ group * block * cohesion_c + reward * effort + school +
    (1 + block | ppn),
  data = df_climate, family = binomial,
  control = ctrl
)

anova(m_cohesion_base, m_cohesion_mod)
summary(m_cohesion_mod)



```


### Model Diagnostics RQ2

```{r}


# Simulate residuals
res2 <- simulateResiduals(final_mod_model, n = 1000)
plot(res2)
testUniformity(res2)
testDispersion(res2)
testZeroInflation(res2)
testOutliers(res2)

# Variance components
VarCorr(final_mod_model)

# ICC
icc_vals <- performance::icc(final_mod_model)
icc_vals

# VIF / collinearity
performance::check_collinearity(final_mod_model)

```

