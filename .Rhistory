knitr::opts_chunk$set(echo = TRUE)
# --- 1. Load packages ---
library(dplyr)
library(tidyr)
library(stringr)
library(lme4)
library(lmerTest)
library(emmeans)
library(car)
library(ggeffects)
library(ggplot2)
library(DHARMa)
library(performance)
library(here)
# --- 2. Import data ---
df_wide <- read.csv(here("data", "raw", "data_2.csv"))
head(df_wide)
# --- 3. Ensure factors ---
df_wide <- df_wide |>
mutate(
ppn = as.factor(ppn),
school = factor(school, levels = c(1, 2, 3)),
class = factor(class),
group = factor(group, levels = c(1, 2, 3),
labels = c("high_norm", "low_norm", "control"))
)
# --- 4. Define SUS item groups ---
sus_items      <- paste0("SUS_", 1:8)
sus_anx_items  <- c("SUS_1", "SUS_3", "SUS_5", "SUS_7")
sus_peer_items <- c("SUS_2", "SUS_4", "SUS_6", "SUS_8")
# --- 5. Convert SUS items to numeric and impute missing values ---
df_wide <- df_wide |>
mutate(across(all_of(sus_items), ~ suppressWarnings(as.numeric(.x))))
# Person-mean imputation
sus_mat <- as.matrix(df_wide[, sus_items, drop = FALSE])
row_means <- rowMeans(sus_mat, na.rm = TRUE)
for (j in seq_along(sus_items)) {
idx <- is.na(sus_mat[, j])
sus_mat[idx, j] <- row_means[idx]
}
df_wide[, sus_items] <- sus_mat
# Compute subscale scores
df_wide <- df_wide |>
mutate(
SUS_social_anxiety    = rowMeans(across(all_of(sus_anx_items))),
SUS_peers_self_esteem = rowMeans(across(all_of(sus_peer_items))),
SUS_total             = rowMeans(across(all_of(sus_items))),
SUS_total_c           = SUS_total - mean(SUS_total, na.rm = TRUE)
)
# --- 6. Identify trial columns ---
trial_pattern <- "^(X)?[12]_(SELF|CLIMATE|OTHERS)_(2|6|10)(easy|hard)(40|90)$"
trial_cols <- names(select(df_wide, matches(trial_pattern)))
# --- 7. Reshape to long format ---
df_long <- df_wide |>
pivot_longer(
cols = all_of(trial_cols),
names_to = "trial",
values_to = "choice_raw"
) |>
mutate(
trial_clean = str_remove(trial, "^X"),
block_num   = as.integer(str_extract(trial_clean, "^[12]")),
target_raw  = str_extract(trial_clean, "(SELF|CLIMATE|OTHERS)"),
reward_num  = as.integer(str_extract(trial_clean, "(?<=_)\\d{1,2}(?=(easy|hard))")),
effort_raw  = as.integer(str_extract(trial_clean, "(40|90)$")),
# Final labeled variables
block  = factor(block_num, levels = c(1, 2), labels = c("pre", "post")),
target = factor(target_raw,
levels = c("SELF", "CLIMATE", "OTHERS"),
labels = c("self", "climate", "prosocial")),
effort = factor(effort_raw, levels = c(40, 90), labels = c("40", "90")),
reward = factor(reward_num, levels = c(2, 6, 10), ordered = TRUE),
choice = case_when(
choice_raw == 1 ~ 1L,  # high-effort choice
choice_raw == 2 ~ 0L,  # low-effort choice
TRUE ~ NA_integer_
),
trial = trial_clean
) |>
select(ppn, school, class, group,
trial, block, target, reward, reward_num,effort,
choice, SUS_social_anxiety,
SUS_peers_self_esteem, SUS_total, SUS_total_c) |>
mutate(
# Reference coding for contrasts
group  = relevel(group, ref = "control"),
target = relevel(target, ref = "self"),
effort = relevel(effort, ref = "40"),
block  = relevel(block,  ref = "pre"),
)
# --- 8. Checks ---
# Check structure
glimpse(df_long)
# Balanced design?
table(df_long$group, df_long$block)
table(df_long$target, df_long$block)
# Missing data
colSums(is.na(df_long))
# Check outcome coding (should be mostly 1s, some 0s)
prop.table(table(df_long$choice))
# --- 9. Save data frames ---
# Save processed data (RDS preserves factors/classes)
saveRDS(df_long, here("data","processed","df_long.rds"))
saveRDS(df_wide, here("data","processed","df_wide.rds"))
install.packages("renv")
renv::init()   # creates renv.lock and renv/ structure
renv::snapshot()
install.packages(c(
"dplyr","tidyr","stringr","lme4","lmerTest","emmeans","car",
"ggeffects","ggplot2","DHARMa","performance","here","ggthemes","scales",
"rmarkdown","knitr"
))
here::here()  # should print the project root
file.exists(here::here("code","1_data_preparation.Rmd"))
file.exists(here::here("data","raw","data_2.csv"))
source(here::here("scripts","render_all.R"))
source(here::here("scripts","load_all.R"))
source(here::here("scripts","render_all.R"))
source(here::here("scripts","render_all.R"))
ctrl <- glmerControl(optimizer="nloptwrap", optCtrl = list(maxfun = 1e6))
m1 <- glmer(
choice ~ target * group * block * reward * effort,
data = df_long, family = binomial, control = ctrl
)
source(here::here("R","_common.R"), local = knitr::knit_global())
# --- 1. Import data ---
df_wide <- read.csv(here("data", "raw", "data_2.csv"))
head(df_wide)
# --- 2. Ensure factors ---
df_wide <- df_wide |>
mutate(
ppn = as.factor(ppn),
school = factor(school, levels = c(1, 2, 3)),
class = factor(class),
group = factor(group, levels = c(1, 2, 3),
labels = c("high_norm", "low_norm", "control"))
)
# --- 3. Define SUS item groups ---
sus_items      <- paste0("SUS_", 1:8)
sus_anx_items  <- c("SUS_1", "SUS_3", "SUS_5", "SUS_7")
sus_peer_items <- c("SUS_2", "SUS_4", "SUS_6", "SUS_8")
# --- 4. Convert SUS items to numeric and impute missing values ---
df_wide <- df_wide |>
mutate(across(all_of(sus_items), ~ suppressWarnings(as.numeric(.x))))
# Person-mean imputation
sus_mat <- as.matrix(df_wide[, sus_items, drop = FALSE])
row_means <- rowMeans(sus_mat, na.rm = TRUE)
for (j in seq_along(sus_items)) {
idx <- is.na(sus_mat[, j])
sus_mat[idx, j] <- row_means[idx]
}
df_wide[, sus_items] <- sus_mat
# Compute subscale scores
df_wide <- df_wide |>
mutate(
SUS_social_anxiety    = rowMeans(across(all_of(sus_anx_items))),
SUS_peers_self_esteem = rowMeans(across(all_of(sus_peer_items))),
SUS_total             = rowMeans(across(all_of(sus_items))),
SUS_total_c           = SUS_total - mean(SUS_total, na.rm = TRUE)
)
# --- 5. Identify trial columns ---
trial_pattern <- "^(X)?[12]_(SELF|CLIMATE|OTHERS)_(2|6|10)(easy|hard)(40|90)$"
trial_cols <- names(select(df_wide, matches(trial_pattern)))
# --- 6. Reshape to long format ---
df_long <- df_wide |>
pivot_longer(
cols = all_of(trial_cols),
names_to = "trial",
values_to = "choice_raw"
) |>
mutate(
trial_clean = str_remove(trial, "^X"),
block_num   = as.integer(str_extract(trial_clean, "^[12]")),
target_raw  = str_extract(trial_clean, "(SELF|CLIMATE|OTHERS)"),
reward_num  = as.integer(str_extract(trial_clean, "(?<=_)\\d{1,2}(?=(easy|hard))")),
effort_raw  = as.integer(str_extract(trial_clean, "(40|90)$")),
# Final labeled variables
block  = factor(block_num, levels = c(1, 2), labels = c("pre", "post")),
target = factor(target_raw,
levels = c("SELF", "CLIMATE", "OTHERS"),
labels = c("self", "climate", "prosocial")),
effort = factor(effort_raw, levels = c(40, 90), labels = c("40", "90")),
reward = factor(reward_num, levels = c(2, 6, 10), ordered = TRUE),
choice = case_when(
choice_raw == 1 ~ 1L,  # high-effort choice
choice_raw == 2 ~ 0L,  # low-effort choice
TRUE ~ NA_integer_
),
trial = trial_clean
) |>
select(ppn, school, class, group,
trial, block, target, reward, reward_num,effort,
choice, SUS_social_anxiety,
SUS_peers_self_esteem, SUS_total, SUS_total_c) |>
mutate(
# Reference coding for contrasts
group  = relevel(group, ref = "control"),
target = relevel(target, ref = "self"),
effort = relevel(effort, ref = "40"),
block  = relevel(block,  ref = "pre"),
)
# --- 7. Checks ---
# Check structure
glimpse(df_long)
# Balanced design?
table(df_long$group, df_long$block)
table(df_long$target, df_long$block)
# Missing data
colSums(is.na(df_long))
# Check outcome coding (should be mostly 1s, some 0s)
prop.table(table(df_long$choice))
m1 <- glmer(
choice ~ target * group * block * reward * effort,
data = df_long, family = binomial, control = ctrl
)
m1 <- glmer(
choice ~ target * group * block * reward * effort * school
+ (1 | ppn) + (1 | class),
data = df_long, family = binomial, control = ctrl
)
m1 <- glmer(
choice ~ target * group * block * reward * effort + school
+ (1 | ppn) + (1 | class),
data = df_long, family = binomial, control = ctrl
)
m1 <- glmer(
choice ~ target + group + block + reward + effort + school
+ reward:effort + target:group:block + target:group:effort:block +
target:group:reward:block
+ (1 | ppn) + (1 | class),
data = df_long, family = binomial, control = ctrl
)
m1 <- glmer(
choice ~ target + group + block + reward + effort + school
+ block:group + target:block:group + (1 | ppn) + (1 | class),
data = df_long, family = binomial, control = ctrl
)
m1 <- glmer(
choice ~ target + group + block + reward + effort + school
+ block:group + (1 | ppn) + (1 | class),
data = df_long, family = binomial, control = ctrl
)
m1 <- glmer(
choice ~ target * group * block * reward * effort + school
+ (1 | ppn) + (1 | class),
data = df_long, family = binomial, control = ctrl
)
source(here::here("R","_common.R"), local = knitr::knit_global())
# Load processed data written by 1_dataprep
df_wide <- readRDS(here::here("data","processed","df_wide.rds"))
df_long <- readRDS(here::here("data","processed","df_long.rds"))
ctrl <- glmerControl(optimizer="bobyqa", optCtrl = list(maxfun = 1e6))
m1 <- glmer(
choice ~ target * group * block * reward * effort + school
+ (1 | ppn) + (1 | class),
data = df_long, family = binomial, control = ctrl
)
m1 <- glmer(
choice ~ target * group * block + reward * effort + school
+ (1 | ppn) + (1 | class),
data = df_long, family = binomial, control = ctrl
)
m1 <- glmer(
choice ~ target * group * block + reward * effort + school
+ (1 | ppn) + (1 | class),
data = df_long, family = binomial, control = ctrl,
verbose = TRUE
)
m2 <- glmer(
choice ~ target * group * block + reward * effort + school
+  (1 + block | ppn) + (1 | class),
data = df_long, family = binomial, control = ctrl
)
VarCorr(m1)
isSingular(m1)
anova(m1, m2, test = "LRT")
m3 <- glmer(
choice ~ target * group * block + reward * effort + school
+  (1 + block | ppn),
data = df_long, family = binomial, control = ctrl
)
anova(m1, m2, m3, test = "LRT")
anova(m1, m2, test = "LRT")
anova(m1, m2, m3, test = "LRT")
?geom_histogram
?ggplot2
