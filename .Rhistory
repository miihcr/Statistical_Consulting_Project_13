ggsave(plot_a,
width = 7,
height = 5, dpi = 300, "figure/descriptives/fig_a_target.png")
# Save all descriptives plots
ggsave(
filename = "figure/descriptives/fig_a_target.png",
plot     = plot_a,
width    = 7,
height   = 5,
dpi      = 300
)
getwd()
# Save all descriptives plots
ggsave(
filename = "figures/descriptives/fig_a_target.png",
plot     = plot_a,
width    = 7,
height   = 5,
dpi      = 300
)
plot_files <- list(
plot_b = "fig_b_effort_x_target.png",
plot_c = "fig_c_reward_x_target.png",
plot_d = "fig_d_reward_x_effort.png",
plot_e = "fig_e_target_x_block_x_group.png"
)
for (nm in names(plot_files)) {
ggsave(
filename = file.path("figures/descriptives", plot_files[[nm]]),
plot     = get(nm),
width    = 7,
height   = 5,
dpi      = 300
)
}
plot_files <- list(
plot_a = "fig_a_target.png",
plot_b = "fig_b_effort_x_target.png",
plot_c = "fig_c_reward_x_target.png",
plot_d = "fig_d_reward_x_effort.png",
plot_e = "fig_e_target_x_block_x_group.png"
)
for (nm in names(plot_files)) {
ggsave(
filename = file.path("figures/descriptives", plot_files[[nm]]),
plot     = get(nm),
width    = 7,
height   = 5,
dpi      = 300
)
}
ggsave("figures/descriptives/fig_a_target.png",  plot_a,
width = 7, height = 5, dpi = 300)
ggsave("figures/descriptives/fig_b_effort_x_target.png",  plot_b,
width = 7, height = 5, dpi = 300)
ggsave("figures/descriptives/fig_c_reward_x_target.png",  plot_c,
width = 7, height = 5, dpi = 300)
ggsave("figures/descriptives/fig_d_reward_x_effort.png",  plot_d,
width = 7, height = 5, dpi = 300)
ggsave("figures/descriptives/fig_e_target_x_block_x_group.png",  plot_e,
width = 7, height = 5, dpi = 300)
ggsave("figures/descriptives/fig_a_target.png",
plot = plot_a,
width = 7, height = 5, dpi = 300)
ggsave("figures/descriptives/fig_b_effort_x_target.png",
plot = plot_b,
width = 7, height = 5, dpi = 300)
ggsave("figures/descriptives/fig_c_reward_x_target.png",
plot = plot_c,
width = 7, height = 5, dpi = 300)
ggsave("figures/descriptives/fig_d_reward_x_effort.png",
plot = plot_d,
width = 7, height = 5, dpi = 300)
ggsave("figures/descriptives/fig_e_target_x_block_x_group.png",     plot = plot_e,
width = 7, height = 5, dpi = 300)
getwd(0)
getwd()
source(here::here("R","_common.R"), local = knitr::knit_global())
source(here::here("scripts","_common.R"), local = knitr::knit_global())
df_wide <- readRDS(here::here("data","processed","df_wide.rds"))
df_long <- readRDS(here::here("data","processed","df_long.rds"))
df_long <- df_long |>
mutate(
group  = relevel(group,  ref = "control"),
target = relevel(target, ref = "self"),
effort = relevel(effort, ref = "40%"),
block  = relevel(block,  ref = "pre")
)
options(contrasts = c("contr.treatment", "contr.poly"))
ctrl <- glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 1e6))
# Baseline model (intercept only)
m0 <- glmer(
choice ~ (1 | ppn) + (1 | class),
data = df_long, family = binomial, control = ctrl
)
# Step 1: Test whether classroom random intercept is needed
m1 <- glmer(
choice ~ target*group*block + reward*effort + school +
(1 | ppn) + (1 | class),
data = df_long, family = binomial, control = ctrl
)
m1_simpler <- glmer(
choice ~ target*group*block + reward*effort + school +
(1 | ppn),
data = df_long, family = binomial, control = ctrl
)
# Compare models
print(anova(m1_simpler, m1, test = "Chisq"))
print(isSingular(m1))
print(VarCorr(m1))
# Step 2: Add random slope for Block
m_full <- glmer(
choice ~ target*group*block + reward*effort + school +
(1 + block | ppn),
data = df_long, family = binomial, control = ctrl
)
# Compare models
print(anova(m1_simpler, m_full, test = "Chisq")) # full model is better
isSingular(m_full)
print(VarCorr(m_full))
# Step 3: test the 3-way interaction
m_no_3way <- glmer(
choice ~ target + group + block +
target:group + target:block + group:block +  # all 2-way interactions
reward * effort + school +
(1 + block | ppn),
data = df_long, family = binomial, control = ctrl
)
anova(m_no_3way, m_full, test = "Chisq") # model without 3way is better
# Choose final model
final_model <- m_full
m0 <- glmer(
choice ~ 1 + (1 + block | ppn),
data = df_long, family = binomial, control = ctrl
)
anova(m_no_3way, m_full, test = "Chisq") # model without 3way is better
# Compare with a baseline model
anova(m0, final_model, test = "Chisq")
summary(final_model)
sjPlot::tab_model(final_model)
install.packages(c("broom.mixed", "modelsummary"))
# install.packages(c("broom.mixed", "modelsummary"))
library(lme4)
library(broom.mixed)
library(modelsummary)
# Basic LaTeX regression table
modelsummary(
list("My GLMM" = final_model),
output = "latex",         # or "clipboard", "markdown", etc
statistic = "({std.error})",
gof_omit = "IC|Log.Lik"   # drop fit indices you don't care about
)
# Basic LaTeX regression table
modelsummary(
list("My GLMM" = final_model),
output = "latex",         # or "clipboard", "markdown", etc
gof_omit = "IC|Log.Lik"   # drop fit indices you don't care about
)
# Basic LaTeX regression table
modelsummary(
list("My GLMM" = final_model),
output = "latex"
)
install.packages("stargazer")
library(stargazer)
stargazer(final_model)
?stargazer
stargazer(final_model,
type = "latex",
style = "ajps",  # American Journal of Political Science style
title = "Mixed-Effects Logistic Regression Predicting High-Effort Choice",
label = "tab:main-model",
align = TRUE,
dep.var.labels = "High-Effort Choice (1 = Yes)",
covariate.labels = c("Target: Climate",
"Target: Prosocial",
"Group: Norm",
"Block: Post",
"Climate × Norm",
"Prosocial × Norm",
"Climate × Post",
"Prosocial × Post",
"Norm × Post",
"Climate × Norm × Post",
"Prosocial × Norm × Post",
"Reward: 6 points",
"Reward: 10 points",
"Effort: 90\\%",
"Reward 6 × Effort 90\\%",
"Reward 10 × Effort 90\\%",
"School"),
star.cutoffs = c(0.05, 0.01, 0.001),
star.char = c("*", "**", "***"),
notes = c("$^{*}$p$<$0.05; $^{**}$p$<$0.01; $^{***}$p$<$0.001",
"Reference levels: Target = Self, Group = Control, Block = Pre,",
"Reward = 2 points, Effort = 40\\%. Random effects: Participant",
"intercepts and slopes for Block. N = [add your N here]."),
notes.append = FALSE,
notes.align = "l",
font.size = "small",
column.sep.width = "3pt",
no.space = TRUE,
omit.stat = c("aic", "bic"),  # Remove AIC/BIC if desired
out = "tables/model_results.tex")
tab_model(final_model,
show.re.var = TRUE,  # Show random effects
show.icc = TRUE,     # Show ICC
show.r2 = FALSE,     # R² not meaningful for logistic
dv.labels = "High-Effort Choice",
pred.labels = c("targetClimate" = "Target: Climate",
"targetProsocial" = "Target: Prosocial",
# ... add all your labels
),
file = "model_table.doc")  # Or .doc for Word
library(sjPlot)
tab_model(final_model,
show.re.var = TRUE,  # Show random effects
show.icc = TRUE,     # Show ICC
show.r2 = FALSE,     # R² not meaningful for logistic
dv.labels = "High-Effort Choice",
pred.labels = c("targetClimate" = "Target: Climate",
"targetProsocial" = "Target: Prosocial",
# ... add all your labels
),
file = "model_table.doc")  # Or .doc for Word
tab_model(final_model,
show.re.var = TRUE,  # Show random effects
show.icc = TRUE,     # Show ICC
show.r2 = FALSE,     # R² not meaningful for logistic
dv.labels = "High-Effort Choice"
)
tab_model(final_model,
show.re.var = TRUE,  # Show random effects
show.icc = TRUE,     # Show ICC
show.r2 = FALSE,     # R² not meaningful for logistic
dv.labels = "High-Effort Choice"
,
file = "model_table.doc"  )
getwd()
summary(final_model)
summary(final_model)
# Odds ratio with 95% CIs
se <- sqrt(diag(vcov(final_model)))
log_odds <- fixef(final_model)
tab <- data.frame(
OR = exp(log_odds),
LL = exp(log_odds - 1.96 * se),
UL = exp(log_odds + 1.96 * se)
)
print(round(tab, 3))
std.err
coefs <- summary(final_model)$ coefficients[, "Estimate"]
std.err <- summary(final_model)$ coefficients[, "Std. Error"]
nams <- rownames(summary(final_model)$ coefficients)
std.err
log_odds <- fixef(final_model)
tab <- data.frame(
OR = exp(log_odds),
se = se,
LL = exp(log_odds - 1.96 * se),
UL = exp(log_odds + 1.96 * se)
)
print(round(tab, 3))
print(round(tab, 4))
print(round(tab, 2))
se
data.frame(se)
round(data.frame(se),2)
performance::check_model(final_model)
performance::check_model(final_model)
citation("performance")
model_performance(final_model)
anova(final_model, m1_simpler)
model_performance(m_no_3way)
check_model(m_no_3way)
model1 <- glmer(
choice ~ group * target + reward * effort +
(1 | school) +
(1 | block) +
(1 | block),     #
family = binomial,
data = df_long
)
summary(model1)
summary(final_model)
df_climate <- df_long |>
filter(target == "climate")
model1 <- glmer(
choice ~ group*block + reward*effort + school +
(1 + block | ppn),
data = df_climate, family = binomial, control = ctrl
)
summary(model1)
model2 <- glmer(
choice ~ group*block + reward*effort + school +
(1 | ppn),
data = df_climate, family = binomial, control = ctrl
)
anova(model1, model2)
model3 <- glmer(
choice ~ group*block + reward*effort + school +
(1 + target + reward + block | ppn),
data = df_climate, family = binomial, control = ctrl
)
model3 <- glmer(
choice ~ group*block + reward*effort + school +
(1 + block || ppn),
data = df_climate, family = binomial, control = ctrl
)
anova(model1, model2, model3)
model_check(model1)
check_model(model1)
check_model(model1)
check_model(model1)
performance::check_model(final_model)
model3 <- glmer(
choice ~ group*block*reward*effort + school +
(1 + block || ppn),
data = df_climate, family = binomial, control = ctrl
)
model4 <- glmer(
choice ~ group * block * target + effort + reward +
(1 + block | ppn) +
(1 | classroom) +
(1 | school),
family = binomial,
control = ctrl,
data = df_long
)
model4 <- glmer(
choice ~ group * block * target + effort + reward +
(1 + block | ppn) +
(1 | class) +
(1 | school),
family = binomial,
control = ctrl,
data = df_long
)
summary(model4)
summary(model4, final_model)
model4 <- glmer(
choice ~ group * block * target + effort + reward + school
(1 + block | ppn) +
(1 | class),
family = binomial,
control = ctrl,
data = df_long
)
model4 <- glmer(
choice ~ group * block * target + effort + reward + school
+ (1 + block | ppn),
family = binomial,
control = ctrl,
data = df_long
)
model5 <- glmer(
choice ~ block * group + effort + reward + school
+ (1 + block | ppn),
family = binomial,
control = ctrl,
data = df_climate
)
anova(model3, model5)
model3 <- glmer(
choice ~ group*block + reward*effort + school +
(1 + block || ppn),
data = df_climate, family = binomial, control = ctrl
)
model6 <- glmer(
choice ~ block * group + effort + reward + school
+ (1 + block || ppn),
family = binomial,
control = ctrl,
data = df_climate
)
anova(model3, model5, model6)
m_uncorr <- glmer(
choice ~ target*group*block + reward*effort + school +
(1 + block || ppn),
data = df_long, family = binomial, control = ctrl
)
anova(final_model, m_uncorr)
m_uncorr2 <- glmer(
choice ~ target*group*block + reward*effort + school +
(1 || ppn),
data = df_long, family = binomial, control = ctrl
)
performance::check_model(final_model)
performance::check_model(final_model)
check_collinearity(final_model)
check_overdispersion(final_model)
check_zeroinflation(final_model)
check_singularity(final_model)
check_heteroscedasticity(final_model)
# 3. Identify problematic predictors
vif_values <- vif(model)
# 3. Identify problematic predictors
vif_values <- vif(final_model)
high_vif <- names(vif_values[vif_values > 10])
print(paste("High VIF predictors:", paste(high_vif, collapse = ", ")))
vif_values
cor(df_wide)
vif(final_model)
check_collinearity(model)
check_collinearity(final_model)
# Model with all 2-way interactions
model_2way <- glmer(
choice ~ target*group + target*block + group*block +
reward*effort + school +
(1 + block | ppn),
data = df_long,
family = binomial,
control = ctrl
)
# Test if the 3-way interaction was significant
anova(final_model, model_2way)
# Check VIF
check_collinearity(model_2way)
check_model(model_2way)
check_model(model_2way)
# Standard error
se <- function(x) sd(x, na.rm = TRUE) / sqrt(sum(!is.na(x)))
# Color palettes consistent across plots
pal_target <- c(
"self"      = "#E15759",
"climate"   = "#59A14F",
"prosocial" = "#4E79A7"
)
pal_group <- c(
"control"       = "#4E79A7",
"positive_norm" = "#59A14F",
"negative_norm" = "#E15759"
)
pd <- position_dodge(width = 0.7)
participant_summary <- df_wide |>
summarise(
N = n(),
N_classes = n_distinct(class),
N_schools = n_distinct(school)
)
participant_summary
susceptibility_descriptives <- df_long |>
summarise(
M   = mean(susceptibility, na.rm = TRUE),
SD  = sd(susceptibility, na.rm = TRUE),
Min = min(susceptibility, na.rm = TRUE),
Max = max(susceptibility, na.rm = TRUE)
)
susceptibility_descriptives
condition_summary <- df_wide |>
group_by(school, group) |>
summarise(n = n(), .groups = "drop") |>
tidyr::pivot_wider(names_from = group, values_from = n, values_fill = 0)
condition_summary
summary_ppn <- df_long |>
group_by(ppn, target, block, group) |>
summarise(prop_per_ppn = mean(choice, na.rm = TRUE), .groups = "drop")
summary_ppn
choice_summary <- summary_ppn |>
group_by(target, block, group) |>
summarise(
n  = n(),
M  = mean(prop_per_ppn, na.rm = TRUE),
SE = se(prop_per_ppn),
.groups = "drop"
)
choice_summary
choice_by_params <- df_long |>
group_by(ppn, reward, effort) |>
summarise(prop_per_ppn = mean(choice, na.rm = TRUE), .groups = "drop") |>
group_by(reward, effort) |>
summarise(
n  = n(),
M  = mean(prop_per_ppn),
SE = se(prop_per_ppn),
.groups = "drop"
)
choice_by_params
a_data <- df_long |>
group_by(ppn, target) |>
summarise(prop_per_ppn = mean(choice, na.rm = TRUE), .groups = "drop") |>
group_by(target) |>
summarise(
prop = mean(prop_per_ppn),
se = se(prop_per_ppn),
n = n(),
.groups = "drop"
)
plot_a <- ggplot(a_data,
aes(x = reorder(target, -prop),
y = prop,
fill = target)) +
geom_bar(stat = "identity", width = 0.6) +
geom_errorbar(aes(ymin = prop - se, ymax = prop + se),
width = 0.15, linewidth = 0.8) +
geom_text(aes(label = scales::percent(prop, accuracy = 1)),
vjust = -1, size = 4) +
scale_fill_manual(values = pal_target) +
scale_y_continuous(labels = scales::percent_format(accuracy = 1),
limits = c(0, 1),
expand = expansion(mult = c(0, 0.1))) +
labs(
x = "Recipient",
y = "Proportion of High-Effort Choices",
fill = "Social target"
) +
theme_minimal(base_size = 12) +
theme(legend.position = "none",
panel.grid.major.x = element_blank())
plot_a
check_overdispersion(final_model)
performance::check_overdispersion(final_model)
