---
title: "3_analysis"
author: "Milena Costa"
date: "2025-11-03"
output: pdf_document
---

```{r setup, include=FALSE}

source(here::here("scripts","_common.R"), local = knitr::knit_global())

df_wide <- readRDS(here::here("data","processed","df_wide.rds"))
df_long <- readRDS(here::here("data","processed","df_long.rds"))

df_long <- df_long |>
  mutate(
    group  = relevel(group,  ref = "control"),
    target = relevel(target, ref = "self"),
    effort = relevel(effort, ref = "40%"),
    block  = relevel(block,  ref = "pre")
  )

options(contrasts = c("contr.treatment", "contr.poly"))

ctrl <- glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 1e6))


```

# 1. Statistical Analysis

## Research Question 1 

Do exposure to social norms about environmental behavior influence children’s effortful pro-environmental choices?

```{r}

# Baseline model (intercept only)

m0 <- glmer(
  choice ~ 1 + (1 + block | ppn),  
  data = df_long, family = binomial, control = ctrl
)

# Step 1: Test whether classroom random intercept is needed

m1 <- glmer(
  choice ~ target*group*block + reward*effort + school +
    (1 | ppn) + (1 | class),
  data = df_long, family = binomial, control = ctrl
)

m1_simpler <- glmer(
  choice ~ target*group*block + reward*effort + school +
    (1 | ppn),
  data = df_long, family = binomial, control = ctrl
)

# Compare models
print(anova(m1_simpler, m1, test = "Chisq"))
print(isSingular(m1))
print(VarCorr(m1))



# Step 2: Add random slope for Block
m_full <- glmer(
  choice ~ target*group*block + reward*effort + school +
    (1 + block | ppn),
  data = df_long, family = binomial, control = ctrl
)

# Compare models

print(anova(m1_simpler, m_full, test = "Chisq")) # full model is better
isSingular(m_full)
print(VarCorr(m_full))


# Step 3: test the 3-way interaction

m_no_3way <- glmer(
  choice ~ target + group + block + 
    target:group + target:block + group:block +  # all 2-way interactions
    reward * effort + school +
    (1 + block | ppn),
  data = df_long, family = binomial, control = ctrl
)

anova(m_no_3way, m_full, test = "Chisq") # model without 3way is better but we retain full model given RQ1


# Choose final model 
final_model <- m_full

summary(final_model)

# Compare with a baseline model
anova(m0, final_model, test = "Chisq")




```


## Model Summary and Odds Ratios

```{r}


print(summary(final_model))

# Overall model fit

print(anova(m0, final_model, test = "Chisq"))

# Odds ratio with 95% CIs
se <- sqrt(diag(vcov(final_model)))

log_odds <- fixef(final_model)
tab <- data.frame(
  OR = exp(log_odds),
  se = se,
  LL = exp(log_odds - 1.96 * se),
  UL = exp(log_odds + 1.96 * se)
)
print(round(tab, 2))

round(data.frame(se),2)


 
coefs <- summary(final_model)$ coefficients[, "Estimate"]
std.err <- summary(final_model)$ coefficients[, "Std. Error"]
nams <- rownames(summary(final_model)$ coefficients)



```


## 2. Post-hoc Analyses 



### 1. Reward $\times$ Effort interaction


```{r}

# dir.create("figures/regression-plots", recursive = TRUE, showWarnings = FALSE)

# 1. Predicted probabilities 

# Predictions for all reward × effort combinations
gg_re <- ggpredict(final_model, terms = c("reward", "effort"))
gg_re


# visualization

int_1 <- plot(gg_re) +
  labs(
    title = "Predicted Probability of High-Effort Choice",
    y = "P(High-Effort Choice)",
    x = "Reward (points)"
  )


ggsave("figures/regression-plots/int_1.png",  
       plot = int_1,
       width = 7, height = 5, dpi = 300)


# 2. Pairwise comparisons

emm_re <- emmeans(final_model, ~ reward * effort, type = "response")

# Reward effects within each effort level
contrast(emm_re, "pairwise", by = "effort", adjust = "holm")

# Effort effects within each reward level
contrast(emm_re, "pairwise", by = "reward", adjust = "holm")


```



### 2. Target $\times$ Group interaction


```{r}

# 1. Predicted probabilities

gg_tg <- ggpredict(final_model, terms = c("target", "group"))
gg_tg

# visualization

int_2 <- plot(gg_tg) +
  labs(
    title = "Predicted Probability of High-Effort Choice",
    y = "P(High-Effort Choice)",
    x = "Social Target"
  )


ggsave("figures/regression-plots/int_2.png",  
       plot = int_2,
       width = 7, height = 5, dpi = 300)

# 2. Pairwise comparisons 

emm_tg <- emmeans(final_model, ~ target * group, type = "response")

# Target differences within each group
contrast(emm_tg, "pairwise", by = "group", adjust = "holm")

# Group differences within each target
contrast(emm_tg, "pairwise", by = "target", adjust = "holm")



```


### 3. Block × Group × Target: Difference-in-Differences Analysis

```{r}

# 1. Predicted probabilities

gg_tgb <- ggpredict(m_full, terms = c("target", "group", "block"))
gg_tgb


# visualization
int_3 <- plot(gg_tgb) +
  labs(
    title = "Predicted Probability of High-Effort Choice",
    y = "P(High-Effort Choice)",
    x = "Block"
  )



ggsave("figures/regression-plots/int_3.png",  
       plot = int_3,
       width = 7, height = 5, dpi = 300)



# Difference in differences 
emm_tgb <- emmeans(m_full, ~ target * group * block, type = "response")

# Pre → Post change within target × group
prepost_tgb <- contrast(
  emm_tgb,
  method = "revpairwise",
  by = c("target", "group"),
  type = "response"
)

# DID: Compare pre-post changes across groups (within each target)
did_by_target <- contrast(
  emm_tgb,
  interaction = c("pairwise", "revpairwise"),
  by = "target",
  adjust = "holm",
  type = "response"
)

# Convert to table for reporting
did_summary <- as.data.frame(did_by_target)
print(did_summary)


```

### Diagnostics (final_model)

```{r}

# 1. Simulate DHARMa residuals

sim <- simulateResiduals(
  fittedModel = final_model,
  n = 1000,
  plot = FALSE
)


# 2. Main diagnostic plots

plot(sim) # QQ + residuals vs fitted

plotQQunif(sim)  # QQ only
plotResiduals(sim) # residuals vs predicted only

# 3. Global statistical tests

testUniformity(sim)      # Should be non-significant
testDispersion(sim)      # Should be non-significant
testOutliers(sim)     # OK if significant for GLMMs, consider type="bootstrap" if significant

# 4. Predictor-specific residual checks

mf <- model.frame(final_model) # because of NA values 


plotResiduals(sim, mf$target)
plotResiduals(sim, mf$group)
plotResiduals(sim, mf$block)


# 5. Grouped residuals (random-effects diagnostic)
sim_ppn <- recalculateResiduals(sim, group = mf$ppn)
plot(sim_ppn)
testDispersion(sim_ppn)


performance::icc(final_model)

performance::r2(final_model)

r2_nakagawa(final_model)

```


```{r}
# Save plots

getwd()

# dir.create("figures/diagnostics", recursive = TRUE, showWarnings = FALSE)


w <- 7
h <- 5
dpi <- 300

# Main dharma plot

png("figures/diagnostics/dharma_main.png", width = w, height = h, units = "in", res = dpi)
plot(sim)
dev.off()


png("figures/diagnostics/dharma_random.png", width = w, height = h, units = "in", res = dpi)
plot(sim_ppn)
dev.off()


png("figures/diagnostics/lattice_random.png", width = w, height = h, units = "in", res = dpi)
randoms1 <- ranef(final_model)
lattice::qqmath(randoms1)
dev.off()


```






## Research Question 2: Moderation Analysis

Are these effects moderated by (a) individual social susceptibility and (b) classroom cohesion?

### Social Susceptibility Moderation

```{r}

# 1. Test whether susceptibility moderates the Group×Block×Target interaction

m_suscept_full <- glmmTMB(
  choice ~ group * block * target * susceptibility_c + 
           reward * effort + school +
    (1 + block | ppn),
  data = df_long, 
  family = binomial
)

summary(m_suscept_full)

# 2, Compare models 

# Model without four-way interaction (all three-ways included)
m_suscept_3way <- glmmTMB(
  choice ~ (group * block * target) + (group * block * susceptibility_c) +
           (group * target * susceptibility_c) + (block * target * susceptibility_c) +
           reward * effort + school +
    (1 + block | ppn),
  data = df_long, 
  family = binomial
)

# Model with only susceptibility × group × block 
m_suscept_simpler <- glmmTMB(
  choice ~ group * block * susceptibility_c + target + 
           target:group + target:block +  # Allow target effects but not moderated by susceptibility
           reward * effort + school +
    (1 + block | ppn),
  data = df_long, 
  family = binomial
)

# Base model: susceptibility main effect only
m_suscept_base <- glmmTMB(
  choice ~ group * block * target + susceptibility_c + 
           reward * effort + school +
    (1 + block | ppn),
  data = df_long, 
  family = binomial
)

# Compare models
print(anova(m_suscept_base, m_suscept_simpler, m_suscept_3way, m_suscept_full, test = "Chisq"))


```


### Classroom Cohesion Moderation

Since cohesion is aggregated, we need the random intercept for class in these models

```{r}

# Full model with four-way interaction + class random effect
m_cohesion_full_class <- glmmTMB(
  choice ~ group * block * target * cohesion_c + 
    reward * effort + school +
    (1 + block | ppn) + (1 | class),
  data = df_long, 
  family = binomial
)

# Check if class random effect is needed
m_cohesion_full_noclass <- glmmTMB(
  choice ~ group * block * target * cohesion_c + 
    reward * effort + school +
    (1 + block | ppn),
  data = df_long, 
  family = binomial
)

print(anova(m_cohesion_full_noclass, m_cohesion_full_class, test = "Chisq"))


# Model with only cohesion × group × block
m_cohesion_simpler_class <- glmmTMB(
  choice ~ group * block * cohesion_c + target + 
    target:group + target:block +
    reward * effort + school +
    (1 + block | ppn) + (1 | class),
  data = df_long, 
  family = binomial
)

# Base model: cohesion main effect only
m_cohesion_base_class <- glmmTMB(
  choice ~ group * block * target + cohesion_c + 
    reward * effort + school +
    (1 + block | ppn) + (1 | class),
  data = df_long, 
  family = binomial
)

# Compare models

print(anova(m_cohesion_base_class, 
            m_cohesion_simpler_class, 
            m_cohesion_full_class, test = "Chisq"))

  
```

### Post-hoc analyses

```{r}

pred <- ggpredict(
  m_suscept_simpler,
  terms = c("group", "susceptibility_c [-1, 0, 1]")
)

model2_plot1 <- plot(pred) +
  ggplot2::theme_bw() +
  ggplot2::labs(
    x = "Group",
    y = "Predicted probability of choice",
    color = "Susceptibility (SD)"
  )


print(model2_plot1)

```


### Model Diagnostics

```{r}
# 1. Simulate DHARMa residuals

sim2 <- simulateResiduals(
  fittedModel = m_suscept_simpler,
  n = 1000,
  plot = FALSE
)


# 2. Main diagnostic plots

plot(sim2) # QQ + residuals vs fitted

plotQQunif(sim2)  # QQ only
plotResiduals(sim2) # residuals vs predicted only

# 3. Global statistical tests

testUniformity(sim2)      # Should be non-significant
testDispersion(sim2)      # Should be non-significant
testOutliers(sim2)       # OK if significant for GLMMs, consider type="bootstrap" if significant

# 4. Predictor-specific residual checks

mf <- model.frame(m_suscept_simpler) # because of NA values 


plotResiduals(sim2, mf$target)
plotResiduals(sim2, mf$group)
plotResiduals(sim2, mf$block)
plotResiduals(sim2, mf$school)
plotResiduals(sim2, mf$reward)
plotResiduals(sim2, mf$effort)


# 5. Grouped residuals (random-effects diagnostic)
sim_ppn2 <- recalculateResiduals(sim2, group = mf$ppn)
plot(sim_ppn2)
testDispersion(sim_ppn2)


performance::icc(m_suscept_simpler)

performance::r2(m_suscept_simpler)

r2_nakagawa(m_suscept_simpler)


```




# Plots 

```{r}

group_labels <- c(
  "control"       = "Control Group",
  "positive_norm" = "Positive Norm",
  "negative_norm" = "Negative Norm"
)

y <- predict_response(
  final_model,
  terms = c("block", "group", "target")
)

y$group <- dplyr::recode(
  y$group,
  !!!group_labels
)


plot_model1 <- plot(y) +
  scale_y_continuous(limits = c(0, 1))


# Plot interaction

ggsave("figures/regression-plots/plot_model1.png",  
       plot = plot_model1,
       width = 7, height = 5, dpi = 300)





```

