---
title: 'Research Question 2: Moderating Variables'
author: "Klavs Kalvenieks"
date: "2025-11-02"
output: pdf_document
---

```{r setup, include=FALSE}
source(here::here("scripts","_common.R"), local = knitr::knit_global())

# Function to extract key fit indices
fit_table <- function(fit) {
data.frame(
ChiSq = fitMeasures(fit, "chisq"),
df = fitMeasures(fit, "df"),
CFI = fitMeasures(fit, "cfi"),
TLI = fitMeasures(fit, "tli"),
RMSEA = fitMeasures(fit, "rmsea"),
SRMR = fitMeasures(fit, "srmr")
)
}

```

## Social susceptibility

```{r}
data <- read.csv(here::here("data","raw","data_2.csv"))

# Calculate SUS scores and check reliability
social_anxiety_items = c("SUS_1","SUS_3","SUS_5","SUS_7")
peers_self_esteem_items = c("SUS_2","SUS_4","SUS_6","SUS_8")
all_items = c("SUS_1", "SUS_2", "SUS_3", "SUS_4",
              "SUS_5", "SUS_6", "SUS_7", "SUS_8")

sus_scores = data[, grep("SUS_", names(data))]

alpha(sus_scores)$total$raw_alpha # cronbachs alpha for total score

omega(sus_scores)$omega.tot # omega for total score 

```

### Reliability analysis (internal consistency)

#### Two factors

```{r}
social_anxiety_rel = psych::alpha(sus_scores[social_anxiety_items], check.keys = FALSE)
alpha_value1 = social_anxiety_rel$total$raw_alpha 
alpha_value1

```

The internal consistency of the Social Anxiety scale: Cronbach’s alpha = `r round(alpha_value1, 3)`

```{r}
self_esteem_rel = psych::alpha(sus_scores[peers_self_esteem_items], check.keys = FALSE)
alpha_value2 = self_esteem_rel$total$raw_alpha
alpha_value2
```

The internal consistency of the Self Esteem scale: Cronbach’s alpha = `r round(alpha_value2, 3)`

Seems like a good fit, test all item reliability.

#### One factor

```{r}
all_items_rel = psych::alpha(sus_scores[all_items], check.keys = FALSE)
alpha_value3 = all_items_rel$total$raw_alpha
alpha_value3
```

Also a good fit, might make sense to combine all of them together. The internal consistency of the all items: Cronbach’s alpha = `r round(alpha_value3, 3)`

comment: I suggest we removed the EFA analysis

### EFA

```{r}
fa.parallel(sus_scores[all_items], fa = "fa")
```

Parallel analysis shows that using two factors is better factor is possible.

### One factor

```{r}
efa_1_factor = fa(sus_scores[all_items], nfactors = 1, rotate = "oblimin")
variance_explained1 = efa_1_factor$Vaccounted["Proportion Var", 1]
efa_1_factor$loadings

```

### Two factors

```{r}
efa_2_factor = fa(sus_scores[all_items], nfactors = 2, rotate = "oblimin")

var_factor1 = efa_2_factor$Vaccounted["Proportion Var", 1]
var_factor2 = efa_2_factor$Vaccounted["Proportion Var", 2]
total_var = efa_2_factor$Vaccounted["Cumulative Var", 2]

# Convert loadings to a proper numeric data frame
loadings_df <- as.data.frame(unclass(efa_2_factor$loadings))

# Assign each item to the factor with the highest absolute loading
loadings_df$main_factor <- apply(loadings_df[, 1:2], 1, function(x) {
  ifelse(abs(x[1]) > abs(x[2]), "Factor1", "Factor2")
})

# Store the main loading value
loadings_df$main_loading <- apply(loadings_df[, 1:2], 1, function(x) max(abs(x)))

var_factor1; var_factor2; total_var
loadings_df

```

We see that 2 factors are also plausible, but second factor does not fit SUS 2,4,6,8. Only SUS 2 and barely SUS 4.

### CFA

```{r}

# 1-factor model

cfa_1f <- "
  GeneralFactor =~ SUS_1 + SUS_2 + SUS_3 + SUS_4 + SUS_5 + SUS_6 + SUS_7 + SUS_8
"

# 2-factor model
cfa_2f <- "
  SocialAnxiety =~ SUS_1 + SUS_3 + SUS_5 + SUS_7
  PeerEsteem    =~ SUS_2 + SUS_4 + SUS_6 + SUS_8
"

# fit_1f = cfa(cfa_1f, data = sus_scores)
# fit_2f = cfa(cfa_2f, data = sus_scores)

fit1 <- cfa(
cfa_1f,
data = sus_scores,
std.lv = TRUE, # factor variances are set to 1 for identification
missing = "fiml" # missing value handling
)


fit2 <- cfa(
cfa_2f,
data = sus_scores,
std.lv = TRUE,
missing = "fiml"
)



summary(fit1, fit.measures = TRUE, standardized = TRUE)
summary(fit2, fit.measures = TRUE, standardized = TRUE)


# Fit measures

fit_table(fit1)

fit_table(fit2)


```

CFA indicates that 2-factor model is significantly better (chi-sq difference test), however the the latent variables are highly correlated (std.lv), therefore it might not make sense to use two

## Social Cohesion

```{r}
data$ppn = as.character(data$ppn)
data$class = as.character(data$class)
data$nom_like = as.character(data$nom_like)

data_sn = subset(data, select = c(ppn, school, class, nom_like))

# Convert comma-separated nominations to list
data_sn$nom_like = strsplit((data_sn$nom_like), ",")
```

```{r}
# Expand to long format
edges = tidyr::unnest(data_sn, cols = c(nom_like))

# Clean up whitespace and remove NA
edges$nom_like = str_trim(edges$nom_like)
edges = subset(edges, nom_like != "" & !is.na(nom_like))

# Create node list (all participants)
nodes = data_sn[, c("ppn", "school", "class")]
colnames(nodes)[1] = "name"   # igraph expects "name" for node IDs

# Rename for clarity
colnames(edges)[colnames(edges) == "nom_like"] = "target"
colnames(edges)[colnames(edges) == "ppn"] = "source"
```

Not all id's are present in dataset, but they have been nominated. Check which one have to be added

### Missing id's

```{r}
# Check per class for nominations not present in ppn
classes = sort(unique(edges$class))

invalid_all = data.frame(name = numeric(), class = numeric(), school = numeric())

for (c in classes) {
  cat("\nClass:", c, "\n")
  
  class_data  = subset(edges, class == c)
  class_nodes = subset(nodes, class == c)
  
  # IDs mentioned but not present
  invalid_ids = setdiff(unique(class_data$target), unique(class_nodes$name))
  
  if (length(invalid_ids) == 0) {
    cat("All nominations in this class refer to existing participants.\n")
  } else {
    cat("Invalid nominations found (does not have ppn in original data):\n")
    print(invalid_ids)
    
    # Store these invalid IDs in a data frame
    temp = data.frame(
      name = invalid_ids,
      class = rep(c, length(invalid_ids)),
      school = unique(class_nodes$school)  # assumes all rows in class_nodes have same school
    )
    invalid_all = rbind(invalid_all, temp)
  }
}
```

```{r}
# Combine invalid nodes with the original node list
nodes_extended = rbind(nodes, invalid_all)
```

### Plots and metrics

```{r}
# Ensure plotting margins
par(mar = c(1, 1, 2, 1))

# Create an empty results data frame
network_summary = data.frame(
  class = character(),
  density_directed = numeric(),
  density_reciprocal = numeric(),
  reciprocity = numeric(),
  transitivity = numeric(),
  path_length_min = numeric(),
  path_length_max = numeric(),
  path_length_mean = numeric(),
  n_components = numeric(),
  largest_component_size = numeric(),
  stringsAsFactors = FALSE
)

# Loop through each class
for (cls in classes) {
  # Subset edges and nodes for this class
  edges_sub = subset(edges, class == cls)
  nodes_sub = subset(nodes_extended, class == cls)
  
  # Build graph including all nodes
  g = graph_from_data_frame(
    d = edges_sub[, c("source", "target", "class", "school")],
    vertices = nodes_sub,
    directed = TRUE
  )
  
  # Compute network metrics

  
  dens = round(edge_density(g, loops = FALSE),3) # directed density
  
  # Reciprocated ties density (undirected)
  g_recip = as.undirected(g, mode = "mutual")
  dens_recip = round(edge_density(g_recip, loops = FALSE), 3)
  
  rec = round(reciprocity(g),3) # Reciprocity (only makes sense for directed graphs)
  trans = round(transitivity(g, type = "global"),3) # Transitivity (global clustering coefficient)
  
  # Shortest path lengths
  dists = distances(g)
  dists[is.infinite(dists)] = NA  # ignore disconnected pairs
  path_min = min(dists, na.rm = TRUE)
  path_max = max(dists, na.rm = TRUE)
  path_mean = round(mean(dists, na.rm = TRUE),3)
  
  # Connected components
  comps = components(g, mode = "weak")
  n_comp = comps$no
  largest_comp = max(comps$csize)
  
  # Store results
  network_summary = rbind(network_summary, data.frame(
    class = cls,
    density_directed = dens,
    density_reciprocal = dens_recip,
    reciprocity = rec,
    transitivity = trans,
    path_length_min = path_min,
    path_length_max = path_max,
    path_length_mean = path_mean,
    n_components = n_comp,
    largest_component_size = largest_comp
  ))
  
  # Plot each network
  plot(
    g,
    main = paste("Directed Network for Class", cls),
    edge.width = 0.5,
    vertex.size = 15,
    vertex.label.cex = 0.8,
    layout = layout_with_fr
  )
  
    plot(
    g_recip,
    main = paste("Reciprocal Network for Class", cls),
    edge.width = 0.5,
    vertex.size = 15,
    vertex.label.cex = 0.8,
    layout = layout_with_fr
  )
}

network_summary

```

```{r}

```


### Network descriptives

Descriptives of each class to see how they compare against each other

```{r}
# Clean nominations column into numeric lists
data_sn$nominations_clean = lapply(data_sn$nom_like, function(x) {
  if (is.null(x) || all(is.na(x))) return(NA)
  as.numeric(unlist(str_extract_all(paste(x, collapse = " "), "\\d+")))
})

# Count number of nominations per subject
data_sn$n_nominations = sapply(data_sn$nominations_clean, function(x) {
  if (all(is.na(x))) 0 else length(x)
})


# Create summary data frame
class_summary = data.frame(
  class = classes,
  n_subjects = NA,
  total_nominations = NA,
  mean_nominations = NA
)

# Loop through classes and compute descriptives
for (i in seq_along(classes)) {
  cls = classes[i]
  sub_df = data_sn[data_sn$class == cls, ]
  
  n_subjects = nrow(sub_df)
  total_nominations = sum(sub_df$n_nominations, na.rm = TRUE)
  mean_nominations = mean(sub_df$n_nominations, na.rm = TRUE)
  
  class_summary[i, "n_subjects"] = n_subjects
  class_summary[i, "total_nominations"] = total_nominations
  class_summary[i, "mean_nominations"] = mean_nominations
}

# View results
print(class_summary)


```
### Adjusting original dataset
```{r}
# Add new column: mean per row (ignore missing values)
data$susceptibility = round(rowMeans(data[, all_items], na.rm = TRUE),2)

# For missing values: Compute class means for susceptibility
class_means = tapply(data$susceptibility, data$class, mean, na.rm = TRUE)

for (i in 1:nrow(data)) {
  if (is.na(data$susceptibility[i])) {
    cls <- data$class[i]
    data$susceptibility[i] <- class_means[as.character(cls)]
  }
}


# Add cohesion (density per class from network_summary)
data = merge(data,
              network_summary[, c("class", "density_directed", "density_reciprocal")],
              by = "class",
              all.x = TRUE)

names(data)[names(data) == "density_reciprocal"] = "cohesion_recip"

names(data)[names(data) == "density_directed"] = "cohesion_directed"

# Center it for the analysis
data$cohesion_recip_c = as.numeric(scale(data$cohesion_recip, center = TRUE, scale = FALSE))

data$cohesion_directed_c = as.numeric(scale(data$cohesion_directed, center = TRUE, scale = FALSE))

data$susceptibility_c = as.numeric(scale(data$susceptibility, center = TRUE, scale = FALSE))

# RDS saves the factors etc 
saveRDS(
  data,
  here::here("data","processed","data2_incl_moderation.rds")
)



```

# Composite score

## Option 1: without PCA

Create a composite score by standardizing it, and afterwards converting it to a 0-100 scale.

```{r}

# Merge network metrics and class descriptives
cohesion_data <- network_summary |> 
  left_join(class_summary, by = "class")


cohesion_data_std <- cohesion_data |> 
  mutate(
    # Standardise (z-scores): (x - mean) / sd
    dens_z           = as.numeric(scale(density_directed)),
    dens_recip_z     = as.numeric(scale(density_reciprocal)),
    reciprocity_z    = as.numeric(scale(reciprocity)),
    transitivity_z   = as.numeric(scale(transitivity)),
    path_mean_z      = as.numeric(scale(path_length_mean)),
    n_comp_z         = as.numeric(scale(n_components)),
    largest_comp_z   = as.numeric(scale(largest_component_size)),
    mean_nom_z       = as.numeric(scale(mean_nominations)),
    
    # flip the metrics for these - higher values should mean more cohesion
    path_mean_coh    = -path_mean_z,   # shorter paths = better
    n_comp_coh       = -n_comp_z       # fewer components = better
  )

cohesion_data_index <- cohesion_data_std |> 
  mutate(
    cohesion_index_z = rowMeans(
      cbind(
        dens_z,
        dens_recip_z,
        reciprocity_z,
        transitivity_z,
        path_mean_coh,
        n_comp_coh,
        largest_comp_z,
        mean_nom_z
      ),
      na.rm = TRUE
    )
  )


# Convert to 0-100 index

cohesion_data_index <- cohesion_data_index |> 
  mutate(
    cohesion_index_01 = (cohesion_index_z - min(cohesion_index_z, na.rm = TRUE)) /
      (max(cohesion_index_z, na.rm = TRUE) - min(cohesion_index_z, na.rm = TRUE)),
    cohesion_index_100 = round(cohesion_index_01 * 100, 1)
  )


cohesion_data_index |> 
  select(class,
         density_directed,
         reciprocity,
         transitivity,
         path_length_mean,
         n_components,
         largest_component_size,
         mean_nominations,
         cohesion_index_100) |> 
  arrange(desc(cohesion_index_100))


```


## Option 2: with PCA

Instead of using them all arbitrarily, we could perform PCA to see which of metrics explain the most amount of variation in cohesion.


Positive indicators: density_directed, density_reciprocal, reciprocity, transitivity, largest_component_size, mean_nominations

Negative indicators: path_length_mean (shorter = better), n_components (fewer = better) - these we will flip before PCA

```{r}

# Merge the data

cohesion_data <- network_summary |> 
  left_join(class_summary, by = "class")

# Prepare variables for PCA

cohesion_vars <- cohesion_data |> 
  mutate(
    path_length_mean = -path_length_mean,  # flip (shorter paths = better)
    n_components     = -n_components       # flip (fewer components = better)
  ) |> 
  select(
    density_directed,
    density_reciprocal,
    reciprocity,
    transitivity,
    path_length_mean,
    n_components,
    largest_component_size,
    mean_nominations
  )

# Standardise variables (required for PCA)
cohesion_scaled <- scale(cohesion_vars)

# Ensure no missing rows
cohesion_scaled <- cohesion_scaled[complete.cases(cohesion_scaled), ]

# Run PCA

pca_res <- prcomp(cohesion_scaled, center = TRUE, scale. = FALSE)


# Check variance explained and loadings

summary(pca_res)

pca_res$rotation

# Extract cohesion index (PC1 scores)

cohesion_data$Cohesion_PC1 <- pca_res$x[,1]

# 0-100 scale

cohesion_data <- cohesion_data |> 
  mutate(
    Cohesion_norm_01 = (Cohesion_PC1 - min(Cohesion_PC1)) /
                       (max(Cohesion_PC1) - min(Cohesion_PC1)),
    Cohesion_norm_100 = round(Cohesion_norm_01 * 100, 1)
  )



```


## Option 3: EFA
```{r}
fa.parallel(cohesion_vars, fa = "fa")
```
Paralell analysis indicates two factors, though the elbow is not very clear.
Generally performing EFA on such a small dataset is not reliable.

Save cohesion data

```{r}

# RDS saves the factors etc 
saveRDS(
  cohesion_data,
  here::here("data","processed","cohesion_data.rds")
)

```

